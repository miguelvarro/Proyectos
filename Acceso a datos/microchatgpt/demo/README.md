# MicroChatGPT (Ollama + Flask)

Aplicaci贸n web que permite interactuar con modelos LLM locales usando Ollama,
con backend en Flask y frontend web moderno.

## Demo
 Ver demo en v铆deo : /demo.mp4

## Caracter铆sticas
- Selecci贸n din谩mica de modelos
- Chat con historial
- Backend propio en Flask
- Integraci贸n con Ollama

## Requisitos
- Python 3.10+
- Ollama instalado

## Ejecuci贸n local
1. ollama run llama3.1:8b-instruct-q4_0
2. python -m venv venv
3. pip install -r requirements.txt
4. python app.py
