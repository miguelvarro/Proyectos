üß† Proyecto 1 ‚Äî Sistema de Similitudes Sem√°nticas + RAG (Ollama + ChromaDB)
1Ô∏è‚É£ Descripci√≥n general

Este proyecto implementa un sistema completo de:

Generaci√≥n de embeddings sem√°nticos usando Ollama (nomic-embed-text)

Almacenamiento vectorial con ChromaDB

Recuperaci√≥n por similitud (top-k)

Sistema RAG (Retrieval-Augmented Generation)

Re-ranking opcional con LLM

Evaluaci√≥n autom√°tica de calidad (groundedness, claridad, etc.)

Ingesta multi-formato (JSON, TXT, MD, PDF)

CLI profesional con m√∫ltiples comandos

Es un pipeline completo de IA sem√°ntica de extremo a extremo.

2Ô∏è‚É£ Arquitectura t√©cnica
Usuario CLI
   ‚îÇ
   ‚ñº
main.py  (orquestador)
   ‚îÇ
   ‚îú‚îÄ‚îÄ src/store.py        ‚Üí ChromaDB (vector store)
   ‚îú‚îÄ‚îÄ src/embedder.py     ‚Üí Ollama embeddings
   ‚îú‚îÄ‚îÄ Ollama /api/chat    ‚Üí generaci√≥n RAG
   ‚îî‚îÄ‚îÄ Evaluaci√≥n LLM      ‚Üí scoring autom√°tico

3Ô∏è‚É£ Componentes del c√≥digo
üîπ src/embedder.py

Responsabilidad:

Generar embeddings mediante POST /api/embeddings de Ollama.

Modelo por defecto: nomic-embed-text.

Flujo:

requests.post("http://localhost:11434/api/embeddings")


Devuelve un vector num√©rico (list[float]) que representa el significado del texto.

üîπ src/store.py ‚Äî Capa de persistencia vectorial

Responsabilidad:

Gestionar la colecci√≥n persistente en ChromaDB.

A√±adir textos con embeddings.

Consultar por similitud.

Eliminar, resetear, estad√≠sticas.

M√©todos clave:

add_text()

Genera embedding.

Inserta en Chroma:

id

document

embedding

metadata

query()

Convierte la consulta en embedding.

Recupera top_k m√°s cercanos (cosine distance).

Permite filtro where por metadatos.

stats()

Cuenta documentos.

Agrupa por autor.

üîπ main.py ‚Äî Orquestador CLI

Es el n√∫cleo del proyecto. Implementa comandos:

Comando	Funci√≥n
init	Inicializa colecci√≥n
add	Inserta texto manual
ingest	Ingesta masiva
query	B√∫squeda sem√°ntica
rag	RAG completo
train	Entrenamiento intensivo
reset	Resetea colecci√≥n
4Ô∏è‚É£ Sistema RAG

El flujo RAG implementado es:

Embedding de pregunta

Recuperaci√≥n top-k

Filtro por:

autor

tag

where JSON

(Opcional) Re-ranking con LLM

Construcci√≥n de prompt con contexto

Generaci√≥n con Ollama

(Opcional) Evaluaci√≥n autom√°tica

5Ô∏è‚É£ Re-ranking LLM

Si se activa --rerank:

Se pasa la pregunta + candidatos al LLM.

El modelo asigna score 0-10.

Se reordenan candidatos.

Se eligen los top_k finales.

Esto mejora relevancia contextual.

6Ô∏è‚É£ Evaluaci√≥n autom√°tica

Con --eval:

Se solicita al modelo que eval√∫e:

groundedness

completeness

clarity

uses_sources

hallucinations

Devuelve JSON estructurado.

7Ô∏è‚É£ Entrenamiento intensivo

python main.py train

Realiza:

Template autom√°tico si frases.json vac√≠o.

Ingesta completa de carpeta data/.

Estad√≠sticas finales.

8Ô∏è‚É£ Nivel t√©cnico alcanzado

Este proyecto ya incluye:

Vector DB real

Embeddings reales

RAG funcional

Re-ranking LLM

Evaluaci√≥n autom√°tica

Filtros estructurados

Persistencia

CLI profesional

Es un proyecto de nivel avanzado / profesional en IA aplicada.